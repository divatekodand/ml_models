{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Zjd_Mr2dPn6x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2a5d4939-46e6-41be-ed4a-0efad2f0b756"
      },
      "cell_type": "code",
      "source": [
        "#MOUNT DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jlCRIwB11UIX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GH-FQO5nvZFO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Logistic Regression as a Neural Network\n",
        "\n",
        "class LogisticRegression:\n",
        "  \n",
        "  def __init__(self,  n_features, n_examples):\n",
        "    self.n_features = n_features\n",
        "    self.n_examples = n_examples\n",
        "    self.w = np.random.randn(self.n_features, 1)\n",
        "    self.b = np.random.randn(1,1)\n",
        "  \n",
        "  # reset - randomly initilize weights to start training3\n",
        "  def reset(self,  n_features, n_examples):\n",
        "    self.n_features = n_features\n",
        "    self.n_examples = n_examples\n",
        "    self.w = np.random.randn(self.n_features, 1)\n",
        "    self.b = np.random.randn(1,1)\n",
        "    \n",
        "  def forward(self, X, y):\n",
        "    n_features = X.shape[0]\n",
        "    n_examples = X.shape[1]\n",
        "    self.X = X\n",
        "    #assert(X.shape == (self.n_features, self.n_examples))\n",
        "    self.z = np.dot(self.w.T, X) + self.b\n",
        "    self.y_hat = 1 / (1 + np.exp(-self.z))\n",
        "    self.y = y\n",
        "    # You dont have to compute the loss for backward pass.\n",
        "    self.loss = 0\n",
        "    for idx in range(n_examples):\n",
        "      if self.y[0, idx] == 1:\n",
        "        self.loss += -np.log(self.y_hat[0, idx])\n",
        "      else:\n",
        "        self.loss += -np.log(1 - self.y_hat[0, idx])\n",
        "    self.loss = self.loss / n_examples\n",
        "    return self.y_hat, self.loss\n",
        "  \n",
        "  def backward(self):\n",
        "    \"\"\"\n",
        "    Returns gradient wrt to w and b (dw and db)\n",
        "    \"\"\"\n",
        "    dz = self.y_hat - self.y\n",
        "    dw = (1.0 / self.n_examples) * np.dot(self.X, dz.T)\n",
        "    db = (1.0 / self.n_examples) * np.sum(dz)\n",
        "    db = db.reshape((1,1))\n",
        "    return dw, db\n",
        "\n",
        "  #Training function - fits model to the data. Trains with the given hyperparameters\n",
        "\n",
        "  def fit(self, X, y, N_EPOCHS, lr, beta, n_iter_lr_decay, lr_decay):\n",
        "    n_features = X.shape[0]\n",
        "    n_examples = X.shape[1]\n",
        "\n",
        "    #logistic_regression = LogisticRegression(n_features, n_examples)\n",
        "\n",
        "\n",
        "    for idx, epoch in enumerate(range(N_EPOCHS)):\n",
        "\n",
        "      y_hat, loss = self.forward(X, y)\n",
        "      if(idx % 50 == 0):\n",
        "        print(\"epoch : \" + str(epoch) + \" ------- Loss : \" + str(loss))\n",
        "\n",
        "      dw, db = self.backward()\n",
        "\n",
        "      #Learning rate decay\n",
        "      if(idx % n_iter_lr_decay == 0):\n",
        "        lr = lr * lr_decay\n",
        "\n",
        "      #Update with weight decay (Weight Decay == l2 regularizarion)\n",
        "      self.w -= (lr * dw + beta * self.w)\n",
        "      self.b -= (lr * db + beta * self.b)\n",
        "\n",
        "    return self.w, self.b\n",
        "  \n",
        "  def infer(self, X, y, threshold):\n",
        "    y_hat, loss = self.forward(X, y)\n",
        "    y_hat_class = []\n",
        "    tp = 0\n",
        "    tn = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    n_examples = y.shape[1]\n",
        "    for i in range(n_examples):\n",
        "      if y_hat[0,i] <= threshold:\n",
        "        y_hat_class.append(0)\n",
        "        if y[0, i] == 0:\n",
        "          tn += 1\n",
        "        else:\n",
        "          fn += 1\n",
        "      else:\n",
        "        y_hat_class.append(1)\n",
        "        if y[0, i] == 0:\n",
        "          fp += 1\n",
        "        else:\n",
        "          tp += 1\n",
        "    \n",
        "    y_hat_class = np.array(y_hat_class)\n",
        "    y_hat_class = y_hat_class.reshape((1, n_examples))\n",
        "    \n",
        "    confusion_dict = {}\n",
        "    \n",
        "    confusion_dict['tp'] = tp / n_examples\n",
        "    confusion_dict['fn'] = fn / n_examples\n",
        "    confusion_dict['tn'] = tn / n_examples\n",
        "    confusion_dict['fp'] = fp / n_examples\n",
        "    \n",
        "    accuracy = (tp + tn) / n_examples\n",
        "    \n",
        "    return y_hat, y_hat_class, loss, accuracy, confusion_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gX63kQrqyd8e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Choose hyperparameters using cross validation\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "#Choose beta using cross validation\n",
        "\n",
        "#hyper_params = (N_EPOCHS, lr, beta, n_iter_lr_decay, lr_decay)\n",
        "def cross_validate(model, X, y, hyper_params, beta_list):\n",
        "  (n_folds, N_EPOCHS, lr, beta, n_iter_lr_decay, lr_decay) = hyper_params\n",
        "  acc_all_param = []\n",
        "  loss_all_param = []\n",
        "  threshold = 0.5\n",
        "  # TODO: Folds are not disjoint \n",
        "  sss = StratifiedShuffleSplit(n_splits=n_folds, test_size=0.25, random_state=0)\n",
        "  for i, hp in enumerate(beta_list):\n",
        "    print(\"beta index : \", i)\n",
        "    acc_per_param = []\n",
        "    loss_per_param = []\n",
        "    X_t, y_t = X.T, y.T\n",
        "    fold = 0\n",
        "    for train_index, test_index in sss.split(X_t, y_t):\n",
        "      print(\"fold : \", fold)\n",
        "      fold += 1\n",
        "      X_train, X_test = X_t[train_index], X_t[test_index]\n",
        "      y_train, y_test = y_t[train_index], y_t[test_index]\n",
        "      \n",
        "      X_train = X_train.T\n",
        "      X_test = X_test.T\n",
        "      y_train = y_train.T\n",
        "      y_test = y_test.T\n",
        "      \n",
        "      model.fit(X_train, y_train, N_EPOCHS, lr, hp, n_iter_lr_decay, lr_decay)\n",
        "      \n",
        "      y_hat, y_hat_class, loss, accuracy, confusion_dict = \\\n",
        "      model.infer(X_test, y_test, threshold)\n",
        "      \n",
        "      acc_per_param.append(accuracy)\n",
        "      loss_per_param.append(loss)\n",
        "      \n",
        "    acc_all_param.append(acc_per_param)\n",
        "    loss_all_param.append(loss_per_param)\n",
        "  \n",
        "  ave_accs = []\n",
        "  for acc in acc_all_param:\n",
        "    ave_accs.append(sum(acc) / len(acc))\n",
        "    \n",
        "  plt.figure(figsize=(12,6))\n",
        "  plt.plot(np.log10(beta_list), ave_accs)\n",
        "  plt.title(\"Plot of cross validation accuracies and regularization factor values (log of reg factors)\")\n",
        "  plt.xlabel(\"log reg factors\")\n",
        "  plt.ylabel(\"Accuracies\")\n",
        "  plt.show()\n",
        "  print(\"Cross Validation Results\")\n",
        "  print(\"Hyper Param values : \")\n",
        "  print(beta_list)  \n",
        "  print(\"Cross Validation Accuracies : \")\n",
        "  print(ave_accs)\n",
        "  \n",
        "  opt_hp = beta_list[ave_accs.index(max(ave_accs))]\n",
        "  print(\"optimal beta : \", opt_hp)\n",
        "  \n",
        "  return opt_hp\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CgZV_Abxv30z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "29554291-8e8d-474c-beaf-4cd9e8732637"
      },
      "cell_type": "code",
      "source": [
        "#Data - Prepare Data\n",
        "# Authentic Bank note dataset\n",
        "# http://archive.ics.uci.edu/ml/datasets/banknote+authentication#\n",
        "\n",
        "data_file = \"/content/drive/My Drive/coursera/deeplearning/\\\n",
        "01_NeuralNetworksandDeepLearning/datasets/data_banknote_authentication.txt\"\n",
        "\n",
        "X_list = []\n",
        "y_list = []\n",
        "\n",
        "f = open(data_file, \"r\")\n",
        "\n",
        "for id,line in enumerate(f):\n",
        "  if line[0] == '#':\n",
        "    continue\n",
        "  else:\n",
        "    example = line.split(\",\")\n",
        "    if example[-1][:-1] == '\\n':\n",
        "      example[-1] = example[-1][:-1]\n",
        "    #print(example)\n",
        "    example = [float(x) for x in example]\n",
        "    X_list.append(example[:-1])\n",
        "    y_list.append(int(example[-1]))\n",
        "#     if id == 6:\n",
        "#       break\n",
        "      \n",
        "X = np.array(X_list)\n",
        "y = np.array(y_list)\n",
        "X = X.T\n",
        "y = y.reshape((1,y.shape[0]))\n",
        "\n",
        "print(\"shape x : \", X.shape, \"shape y : \", y.shape)\n",
        "# print(X,y)\n",
        "\n",
        "#Send X.T to the shuffling function, and y should be (m,1)\n",
        "def shuffle_in_unison(a, b):\n",
        "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
        "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
        "    permutation = np.random.permutation(a.shape[0])\n",
        "#     print(\"permutation: \", permutation)\n",
        "    for old_index, new_index in enumerate(permutation):\n",
        "#       print(old_index, new_index)\n",
        "      shuffled_a[new_index] = a[old_index]\n",
        "      shuffled_b[new_index] = b[old_index]\n",
        "#     print(a)\n",
        "#     print(\"shuffled\")\n",
        "#     print(shuffled_a)\n",
        "    return shuffled_a.T, shuffled_b.T\n",
        "  \n",
        "X, y =   shuffle_in_unison(X.T, y.T)\n",
        "print(\"After shuffling\")\n",
        "print(\"shape x : \", X.shape, \"shape y : \", y.shape)    \n",
        "\n",
        "# print(X, y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape x :  (4, 1372) shape y :  (1, 1372)\n",
            "After shuffling\n",
            "shape x :  (4, 1372) shape y :  (1, 1372)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UmQecIK1UtWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2970
        },
        "outputId": "f1d9bb1e-357c-415f-94a0-c972cdced4f2"
      },
      "cell_type": "code",
      "source": [
        "#Final Training and Testing\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Default parameter values\n",
        "N_EPOCHS = 200\n",
        "lr = 0.03\n",
        "beta = 0.0001   # Regularization factor\n",
        "n_iter_lr_decay = 80\n",
        "lr_decay = 0.9\n",
        "n_folds = 4\n",
        "beta_list =  [0.01, 0.001, 0.0001, 0.00001, 0.000001, 1e-10]\n",
        "\n",
        "logistic_regr = LogisticRegression(X.shape[0], X.shape[1])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "     X.T, y.T, test_size=0.3, random_state=0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = X_train.T, X_test.T, y_train.T, y_test.T \n",
        "\n",
        "print(\"-----------Cross Validation-----------\")\n",
        "hyper_params = (n_folds, N_EPOCHS, lr, beta, n_iter_lr_decay, lr_decay)\n",
        "opt_beta = cross_validate(logistic_regr, X_train, y_train, hyper_params, beta_list)\n",
        "\n",
        "print(\"-----------Final Train and Test-----------\")\n",
        "logistic_regr.fit(X_train, y_train, N_EPOCHS, lr, opt_beta, n_iter_lr_decay, lr_decay)\n",
        "\n",
        "threshold = 0.5\n",
        "y_hat, y_hat_class, loss, accuracy, confusion_dict = \\\n",
        "      logistic_regr.infer(X_test, y_test, threshold)\n",
        "\n",
        "precision = confusion_dict['tp'] / (confusion_dict['tp'] + confusion_dict['fp'])\n",
        "recall = confusion_dict['tp'] / (confusion_dict['tp'] + confusion_dict['fn'])\n",
        "f1_score = (2*precision*recall) / (precision + recall)\n",
        "\n",
        "print(\"------------Final Results-----------------\")\n",
        "print(\"Test set size : \", y_test.shape[1])\n",
        "print(\"Num positive in test set : \", np.sum(y_test))\n",
        "print(\"Test Accuracy : \", accuracy)\n",
        "print(\"Test loss : \", loss)\n",
        "print(\"Confusion matrix : \")\n",
        "for key in confusion_dict.keys():\n",
        "  print(key, \" : \", confusion_dict[key])\n",
        "print(\"Precision : \", precision)\n",
        "print(\"Recall : \", recall)\n",
        "print(\"F1 Score: \", f1_score)\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------Cross Validation-----------\n",
            "beta index :  0\n",
            "fold :  0\n",
            "epoch : 0 ------- Loss : 3.8725634843279337\n",
            "epoch : 50 ------- Loss : 0.4471930358689712\n",
            "epoch : 100 ------- Loss : 0.3242890881688688\n",
            "epoch : 150 ------- Loss : 0.30662133269949343\n",
            "fold :  1\n",
            "epoch : 0 ------- Loss : 0.308221754039702\n",
            "epoch : 50 ------- Loss : 0.29259743229757507\n",
            "epoch : 100 ------- Loss : 0.28985712822306464\n",
            "epoch : 150 ------- Loss : 0.2912708998701958\n",
            "fold :  2\n",
            "epoch : 0 ------- Loss : 0.29531745064295883\n",
            "epoch : 50 ------- Loss : 0.2837229634311754\n",
            "epoch : 100 ------- Loss : 0.2831736801416116\n",
            "epoch : 150 ------- Loss : 0.285953718841951\n",
            "fold :  3\n",
            "epoch : 0 ------- Loss : 0.29417498108900597\n",
            "epoch : 50 ------- Loss : 0.2857981847947513\n",
            "epoch : 100 ------- Loss : 0.2864991177744911\n",
            "epoch : 150 ------- Loss : 0.2897042764460233\n",
            "beta index :  1\n",
            "fold :  0\n",
            "epoch : 0 ------- Loss : 0.2945495865803828\n",
            "epoch : 50 ------- Loss : 0.22855424358951112\n",
            "epoch : 100 ------- Loss : 0.1994600125434513\n",
            "epoch : 150 ------- Loss : 0.18319144617297164\n",
            "fold :  1\n",
            "epoch : 0 ------- Loss : 0.1750003133393734\n",
            "epoch : 50 ------- Loss : 0.1639910718051005\n",
            "epoch : 100 ------- Loss : 0.1566281360087291\n",
            "epoch : 150 ------- Loss : 0.15157948045678424\n",
            "fold :  2\n",
            "epoch : 0 ------- Loss : 0.1461400790815524\n",
            "epoch : 50 ------- Loss : 0.14117676109756486\n",
            "epoch : 100 ------- Loss : 0.13784207854104613\n",
            "epoch : 150 ------- Loss : 0.13559249182505212\n",
            "fold :  3\n",
            "epoch : 0 ------- Loss : 0.13967311797107232\n",
            "epoch : 50 ------- Loss : 0.13721164648833004\n",
            "epoch : 100 ------- Loss : 0.1355040842421042\n",
            "epoch : 150 ------- Loss : 0.13448399015897722\n",
            "beta index :  2\n",
            "fold :  0\n",
            "epoch : 0 ------- Loss : 0.13082994973939038\n",
            "epoch : 50 ------- Loss : 0.12371266509058422\n",
            "epoch : 100 ------- Loss : 0.11807945922052501\n",
            "epoch : 150 ------- Loss : 0.11359890768778746\n",
            "fold :  1\n",
            "epoch : 0 ------- Loss : 0.11051057595622447\n",
            "epoch : 50 ------- Loss : 0.1058925940023279\n",
            "epoch : 100 ------- Loss : 0.10238778851223698\n",
            "epoch : 150 ------- Loss : 0.09948512556169103\n",
            "fold :  2\n",
            "epoch : 0 ------- Loss : 0.09517359923236535\n",
            "epoch : 50 ------- Loss : 0.092025489268556\n",
            "epoch : 100 ------- Loss : 0.08966862027335964\n",
            "epoch : 150 ------- Loss : 0.087678330932965\n",
            "fold :  3\n",
            "epoch : 0 ------- Loss : 0.09234569560229852\n",
            "epoch : 50 ------- Loss : 0.09044128211589436\n",
            "epoch : 100 ------- Loss : 0.08877515518524787\n",
            "epoch : 150 ------- Loss : 0.08734315924157356\n",
            "beta index :  3\n",
            "fold :  0\n",
            "epoch : 0 ------- Loss : 0.0828752714328551\n",
            "epoch : 50 ------- Loss : 0.08100614553638831\n",
            "epoch : 100 ------- Loss : 0.07935598681560026\n",
            "epoch : 150 ------- Loss : 0.07790678611785669\n",
            "fold :  1\n",
            "epoch : 0 ------- Loss : 0.07633741104656236\n",
            "epoch : 50 ------- Loss : 0.07423310460045426\n",
            "epoch : 100 ------- Loss : 0.07281394152856688\n",
            "epoch : 150 ------- Loss : 0.07158628615322238\n",
            "fold :  2\n",
            "epoch : 0 ------- Loss : 0.06865809766548663\n",
            "epoch : 50 ------- Loss : 0.0670344980558467\n",
            "epoch : 100 ------- Loss : 0.06588911267491224\n",
            "epoch : 150 ------- Loss : 0.06489133571344835\n",
            "fold :  3\n",
            "epoch : 0 ------- Loss : 0.07069642221897934\n",
            "epoch : 50 ------- Loss : 0.06969199962403916\n",
            "epoch : 100 ------- Loss : 0.0687796638114962\n",
            "epoch : 150 ------- Loss : 0.06796290769468957\n",
            "beta index :  4\n",
            "fold :  0\n",
            "epoch : 0 ------- Loss : 0.06417039587418794\n",
            "epoch : 50 ------- Loss : 0.06327309274872854\n",
            "epoch : 100 ------- Loss : 0.06248434582975852\n",
            "epoch : 150 ------- Loss : 0.06177598083661671\n",
            "fold :  1\n",
            "epoch : 0 ------- Loss : 0.0604684892018357\n",
            "epoch : 50 ------- Loss : 0.05910055530989252\n",
            "epoch : 100 ------- Loss : 0.05832524170667566\n",
            "epoch : 150 ------- Loss : 0.05766939825325643\n",
            "fold :  2\n",
            "epoch : 0 ------- Loss : 0.055187951486820104\n",
            "epoch : 50 ------- Loss : 0.054182401680737305\n",
            "epoch : 100 ------- Loss : 0.053524407090813776\n",
            "epoch : 150 ------- Loss : 0.052956511920498515\n",
            "fold :  3\n",
            "epoch : 0 ------- Loss : 0.05925996194197482\n",
            "epoch : 50 ------- Loss : 0.05866980457277897\n",
            "epoch : 100 ------- Loss : 0.05812806133251161\n",
            "epoch : 150 ------- Loss : 0.05763701654332527\n",
            "beta index :  5\n",
            "fold :  0\n",
            "epoch : 0 ------- Loss : 0.05428903930482979\n",
            "epoch : 50 ------- Loss : 0.05373157842265274\n",
            "epoch : 100 ------- Loss : 0.05326088599707975\n",
            "epoch : 150 ------- Loss : 0.05283689963454087\n",
            "fold :  1\n",
            "epoch : 0 ------- Loss : 0.05158195075654421\n",
            "epoch : 50 ------- Loss : 0.0505373921579283\n",
            "epoch : 100 ------- Loss : 0.05002625454369763\n",
            "epoch : 150 ------- Loss : 0.049613369629576506\n",
            "fold :  2\n",
            "epoch : 0 ------- Loss : 0.047271583940686264\n",
            "epoch : 50 ------- Loss : 0.046565804306717834\n",
            "epoch : 100 ------- Loss : 0.04613146748122311\n",
            "epoch : 150 ------- Loss : 0.04576441324881682\n",
            "fold :  3\n",
            "epoch : 0 ------- Loss : 0.05230044050584675\n",
            "epoch : 50 ------- Loss : 0.05191189175662374\n",
            "epoch : 100 ------- Loss : 0.05155453485306234\n",
            "epoch : 150 ------- Loss : 0.051228944237493315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAGCCAYAAADAElSHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc95751a908>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Cross Validation Results\n",
            "Hyper Param values : \n",
            "[0.01, 0.001, 0.0001, 1e-05, 1e-06, 1e-10]\n",
            "Cross Validation Accuracies : \n",
            "[0.9354166666666667, 0.9697916666666667, 0.9729166666666667, 0.9770833333333333, 0.9833333333333334, 0.984375]\n",
            "optimal beta :  1e-10\n",
            "-----------Final Train and Test-----------\n",
            "epoch : 0 ------- Loss : 0.04934321119156762\n",
            "epoch : 50 ------- Loss : 0.04883056653053941\n",
            "epoch : 100 ------- Loss : 0.048391429224542135\n",
            "epoch : 150 ------- Loss : 0.04800128633598783\n",
            "------------Final Results-----------------\n",
            "Test set size :  412\n",
            "Num positive in test set :  184\n",
            "Test Accuracy :  0.9878640776699029\n",
            "Test loss :  0.04946755951904038\n",
            "Confusion matrix : \n",
            "tp  :  0.4393203883495146\n",
            "fn  :  0.007281553398058253\n",
            "tn  :  0.5485436893203883\n",
            "fp  :  0.0048543689320388345\n",
            "Precision :  0.9890710382513661\n",
            "Recall :  0.9836956521739131\n",
            "F1 Score:  0.9863760217983651\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}